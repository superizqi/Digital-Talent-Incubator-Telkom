{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hate Speech Detection\n",
    "\n",
    "Here the model the classification model from Indonesian Hate Speech Dataet (https://github.com/ialfina/id-hatespeech-detection).\n",
    "We will create model to detect hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install Sastrawi\n",
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RIZQI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RIZQI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "0  Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...\n",
       "1  Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...\n",
       "2  Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...\n",
       "3  Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...\n",
       "4  Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P..."
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/hate-speech/IDHSD_RIO_unbalanced_713_2017.txt', sep='\\t', header=None, names=['label', 'tweet'], skiprows=1, engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 713 entries, 0 to 712\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   713 non-null    object\n",
      " 1   tweet   713 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x263a10c68e0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x='label', kind='count', data=df, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      1  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...\n",
       "1      1  RT @baguscondromowo: Mereka terus melukai aksi...\n",
       "2      1  Sylvi: bagaimana gurbernur melakukan kekerasan...\n",
       "3      1  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...\n",
       "4      1  RT @lisdaulay28: Waspada KTP palsu.....kawal P..."
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = le.transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      1  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...\n",
       "1      1  RT @baguscondromowo: Mereka terus melukai aksi...\n",
       "2      1  Sylvi: bagaimana gurbernur melakukan kekerasan...\n",
       "3      1  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...\n",
       "4      1  RT @lisdaulay28: Waspada KTP palsu.....kawal P..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_filtering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "      <td>RT spardaxyz Fadli Zon Minta Mendagri Segera M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "      <td>RT baguscondromowo Mereka terus melukai aksi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "      <td>Sylvi bagaimana gurbernur melakukan kekerasan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada Masalah Jal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "      <td>RT lisdaulay28 Waspada KTP palsu kawal PILKADA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      1  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...   \n",
       "1      1  RT @baguscondromowo: Mereka terus melukai aksi...   \n",
       "2      1  Sylvi: bagaimana gurbernur melakukan kekerasan...   \n",
       "3      1  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...   \n",
       "4      1  RT @lisdaulay28: Waspada KTP palsu.....kawal P...   \n",
       "\n",
       "                                     tweet_filtering  \n",
       "0  RT spardaxyz Fadli Zon Minta Mendagri Segera M...  \n",
       "1  RT baguscondromowo Mereka terus melukai aksi d...  \n",
       "2  Sylvi bagaimana gurbernur melakukan kekerasan ...  \n",
       "3  Ahmad Dhani Tak Puas Debat Pilkada Masalah Jal...  \n",
       "4  RT lisdaulay28 Waspada KTP palsu kawal PILKADA...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering\n",
    "def filtering(tweet):\n",
    "    result = re.sub('[^A-Za-z0-9]+', ' ', tweet)\n",
    "    result = re.sub('https ', '', result)\n",
    "    return result\n",
    "\n",
    "df['tweet_filtering'] = df['tweet'].apply(filtering)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_filtering</th>\n",
       "      <th>tweet_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "      <td>RT spardaxyz Fadli Zon Minta Mendagri Segera M...</td>\n",
       "      <td>rt spardaxyz fadli zon minta mendagri segera n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "      <td>RT baguscondromowo Mereka terus melukai aksi d...</td>\n",
       "      <td>rt baguscondromowo mereka terus luka aksi dala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "      <td>Sylvi bagaimana gurbernur melakukan kekerasan ...</td>\n",
       "      <td>sylvi bagaimana gurbernur laku keras perempuan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada Masalah Jal...</td>\n",
       "      <td>ahmad dhani tak puas debat pilkada masalah jal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "      <td>RT lisdaulay28 Waspada KTP palsu kawal PILKADA...</td>\n",
       "      <td>rt lisdaulay28 waspada ktp palsu kawal pilkada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      1  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...   \n",
       "1      1  RT @baguscondromowo: Mereka terus melukai aksi...   \n",
       "2      1  Sylvi: bagaimana gurbernur melakukan kekerasan...   \n",
       "3      1  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...   \n",
       "4      1  RT @lisdaulay28: Waspada KTP palsu.....kawal P...   \n",
       "\n",
       "                                     tweet_filtering  \\\n",
       "0  RT spardaxyz Fadli Zon Minta Mendagri Segera M...   \n",
       "1  RT baguscondromowo Mereka terus melukai aksi d...   \n",
       "2  Sylvi bagaimana gurbernur melakukan kekerasan ...   \n",
       "3  Ahmad Dhani Tak Puas Debat Pilkada Masalah Jal...   \n",
       "4  RT lisdaulay28 Waspada KTP palsu kawal PILKADA...   \n",
       "\n",
       "                                      tweet_stemming  \n",
       "0  rt spardaxyz fadli zon minta mendagri segera n...  \n",
       "1  rt baguscondromowo mereka terus luka aksi dala...  \n",
       "2  sylvi bagaimana gurbernur laku keras perempuan...  \n",
       "3  ahmad dhani tak puas debat pilkada masalah jal...  \n",
       "4  rt lisdaulay28 waspada ktp palsu kawal pilkada...  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "def stemming(tweet):\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    result = stemmer.stem(tweet)\n",
    "    return result\n",
    "\n",
    "df['tweet_stemming'] = df['tweet_filtering'].apply(stemming)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "sw = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words=sw)\n",
    "x = df['tweet_stemming']\n",
    "y = df['label']\n",
    "\n",
    "# vectorizer\n",
    "x = vect.fit_transform(x)\n",
    "\n",
    "# secara default 75 25\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model = []\n",
    "list_acc = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "def evaluation(m):\n",
    "    model = m\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = round(metrics.accuracy_score(y_test, y_pred),2)\n",
    "    prec = round(metrics.precision_score(y_test, y_pred),2)\n",
    "    recall = round(metrics.recall_score(y_test, y_pred),2)\n",
    "    list_model.append(str(model).split('(')[0])\n",
    "    list_acc.append(acc)\n",
    "    list_precision.append(prec)\n",
    "    list_recall.append(recall)\n",
    "    #print(f\"\"\"{str(model).split('(')[0]} \\nAccuracy : {acc} \\nPrecision : {prec} \\nRecall : {recall}\"\"\")\n",
    "    print(f\"\"\"Algorithm : {str(model).split('(')[0]} \\n {classification_report(y_test,y_pred)} \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : SVC \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.55      0.71        65\n",
      "           1       0.80      0.99      0.88       114\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.88      0.77      0.79       179\n",
      "weighted avg       0.86      0.83      0.82       179\n",
      " \n"
     ]
    }
   ],
   "source": [
    "evaluation(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : KNeighborsClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75        65\n",
      "           1       0.84      0.91      0.87       114\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.80      0.81       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      " \n"
     ]
    }
   ],
   "source": [
    "evaluation(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : DecisionTreeClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73        65\n",
      "           1       0.83      0.90      0.87       114\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.79      0.80       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      " \n"
     ]
    }
   ],
   "source": [
    "evaluation(tree.DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.60      0.74        65\n",
      "           1       0.81      0.99      0.89       114\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.89      0.80      0.82       179\n",
      "weighted avg       0.87      0.85      0.84       179\n",
      " \n"
     ]
    }
   ],
   "source": [
    "evaluation(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritma</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algoritma  Accuracy  Precision  Recall\n",
       "3  RandomForestClassifier      0.86       0.82    0.99\n",
       "0                     SVC      0.83       0.80    0.99\n",
       "1    KNeighborsClassifier      0.83       0.84    0.91\n",
       "2  DecisionTreeClassifier      0.80       0.84    0.85"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame({'Algoritma' : list_model, 'Accuracy' : list_acc, 'Precision' : list_precision, 'Recall' : list_recall})\n",
    "df_summary.sort_values(by='Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Initiation\n",
    "model = RandomForestClassifier()\n",
    "round(cross_val_score(model,x,y,cv=20).mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 100}\n",
      "0.8317837092484981\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {'criterion' : ['gini','entropy'],\n",
    "'max_features' : ['auto','sqrt','log2'],\n",
    "'n_estimators' : [100,200,300],\n",
    "'class_weight' : ['balanced','balanced_subsample']}\n",
    "\n",
    "gsv = GridSearchCV(RandomForestClassifier(),param_grid=param_grid,n_jobs=4,cv=5)\n",
    "gsv.fit(x,y)\n",
    "print(gsv.best_params_)\n",
    "print(gsv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75        42\n",
      "           1       0.98      0.82      0.89       137\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.80      0.88      0.82       179\n",
      "weighted avg       0.90      0.85      0.86       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**gsv.best_params_)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219639515414163"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model,x,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the prediction process using Random Forest Classifier Algorithm and evaluation process using cross validation, it obtained accuracy of **82.19%**. This means that this algorithm has an error tolerance of **17.81 %**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
